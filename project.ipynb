{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Hand Detection and Finger Counting using OpenCV and MediaPipe\n",
    "\n",
    "This notebook demonstrates a method for **real-time hand detection** and **finger counting** using **computer vision** and **machine learning** tools. We leverage **MediaPipe**, a framework developed by Google, which provides robust hand-tracking solutions, and **OpenCV** for image processing. \n",
    "\n",
    "This technique has applications in **human-computer interaction (HCI)**, **sign language recognition**, and even in **gesture-based control systems**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for image processing and hand tracking\n",
    "import cv2  # OpenCV for real-time computer vision\n",
    "import mediapipe as mp  # MediaPipe for hand tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Overview\n",
    "\n",
    "- **OpenCV (cv2):** A library designed for real-time image processing. We use it for handling camera input and displaying the processed image with detected hands.\n",
    "  \n",
    "- **MediaPipe (mp):** A cross-platform framework that provides efficient and fast hand-tracking algorithms. The `Hands` model from MediaPipe will detect multiple hands and their key landmarks in each frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class for hand detection and finger counting\n",
    "class handDetector():\n",
    "    def __init__(self, mode=False, maxHands=2, detectionCon=0.5, trackCon=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the handDetector class with parameters for:\n",
    "        - mode: Whether to treat the input as a static image or a video stream.\n",
    "        - maxHands: Maximum number of hands to detect.\n",
    "        - detectionCon: Minimum confidence value for hand detection.\n",
    "        - trackCon: Minimum confidence value for hand tracking.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "\n",
    "        # Initialize the MediaPipe Hands module and its drawing utilities\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(static_image_mode=self.mode,\n",
    "                                        max_num_hands=self.maxHands,\n",
    "                                        min_detection_confidence=self.detectionCon,\n",
    "                                        min_tracking_confidence=self.trackCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "        # Landmark indices for fingertips (thumb, index, middle, ring, pinky)\n",
    "        self.tipIds = [4, 8, 12, 16, 20]\n",
    "\n",
    "    def findHands(self, img, draw=True):\n",
    "        \"\"\"\n",
    "        Process the input image to detect hands. Optionally, draw landmarks.\n",
    "        - img: Input image (frame from video stream).\n",
    "        - draw: Boolean to determine if landmarks should be drawn on the image.\n",
    "        \"\"\"\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert image to RGB\n",
    "        self.results = self.hands.process(imgRGB)  # Process the image with MediaPipe\n",
    "        \n",
    "        if self.results.multi_hand_landmarks:  # Check if any hands are detected\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "\n",
    "    def findPosition(self, img, handNo=0, draw=True):\n",
    "        \"\"\"\n",
    "        Retrieve the positions of the landmarks of the detected hands.\n",
    "        - img: Input image (frame).\n",
    "        - handNo: Hand index to extract landmarks from.\n",
    "        - draw: Boolean to draw circles on landmarks.\n",
    "        \"\"\"\n",
    "        lmList = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                h, w, c = img.shape  # Image dimensions\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)  # Convert normalized coordinates to pixel values\n",
    "                lmList.append([id, cx, cy])\n",
    "                if draw:\n",
    "                    cv2.circle(img, (cx, cy), 10, (255, 0, 255), cv2.FILLED)  # Draw circles on the landmarks\n",
    "        return lmList\n",
    "\n",
    "    def fingersUp(self, lmList, handType):\n",
    "        \"\"\"\n",
    "        Determine which fingers are up by analyzing landmark positions.\n",
    "        - lmList: List of landmarks for a hand.\n",
    "        - handType: Either 'Left' or 'Right' for the handedness of the hand.\n",
    "        \"\"\"\n",
    "        fingers = []\n",
    "        \n",
    "        # Thumb detection varies depending on left or right hand\n",
    "        if handType == \"Right\":\n",
    "            fingers.append(1 if lmList[self.tipIds[0]][1] < lmList[self.tipIds[0] - 1][1] else 0)\n",
    "        else:\n",
    "            fingers.append(1 if lmList[self.tipIds[0]][1] > lmList[self.tipIds[0] - 1][1] else 0)\n",
    "\n",
    "        # Detect if other fingers are up\n",
    "        for id in range(1, 5):\n",
    "            fingers.append(1 if lmList[self.tipIds[id]][2] < lmList[self.tipIds[id] - 2][2] else 0)\n",
    "\n",
    "        return fingers\n",
    "\n",
    "    def getHandType(self, handIndex):\n",
    "        \"\"\"\n",
    "        Retrieve the type of hand (left or right) based on handedness classification.\n",
    "        - handIndex: Index of the detected hand in the results.\n",
    "        \"\"\"\n",
    "        if self.results.multi_handedness:\n",
    "            handType = self.results.multi_handedness[handIndex].classification[0].label\n",
    "            return handType\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Detector Class Overview\n",
    "\n",
    "The `handDetector` class encapsulates the functionality for:\n",
    "\n",
    "- **Detecting hands:** Converts the input image to RGB, processes it with MediaPipe, and detects hand landmarks.\n",
    "- **Finding positions:** Returns pixel coordinates of the hand landmarks.\n",
    "- **Determining finger state:** Checks if each finger is up by analyzing landmark positions.\n",
    "- **Classifying hand type:** Identifies if the detected hand is left or right based on MediaPipe's classification.\n",
    "\n",
    "This modular approach allows for easy detection and tracking of multiple hands in real-time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "# Main function for real-time video capture and processing\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)  # Start video capture from the webcam\n",
    "    detector = handDetector()   # Create an instance of the hand detector\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read()  # Read the current frame from the webcam\n",
    "        img = detector.findHands(img)  # Detect hands in the frame\n",
    "        \n",
    "        totalFingers = 0  # Initialize total finger count\n",
    "\n",
    "        if detector.results.multi_hand_landmarks:  # If hands are detected\n",
    "            for handIndex, handLms in enumerate(detector.results.multi_hand_landmarks):\n",
    "                lmList = detector.findPosition(img, handIndex)  # Get landmark positions\n",
    "                handType = detector.getHandType(handIndex)  # Identify hand type (left or right)\n",
    "                if handType:\n",
    "                    fingers = detector.fingersUp(lmList, handType)  # Determine which fingers are up\n",
    "                    totalFingers += fingers.count(1)  # Count how many fingers are up for this hand\n",
    "\n",
    "        # Display the total number of fingers raised\n",
    "        cv2.putText(img, f'Total Fingers: {totalFingers}', (10, 100), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 3)\n",
    "\n",
    "        cv2.imshow(\"Image\", img)  # Show the processed frame with the finger count\n",
    "        cv2.waitKey(1)  # Wait for 1 millisecond before processing the next frame\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function for Real-Time Finger Counting\n",
    "\n",
    "- **Video Capture:** Uses `cv2.VideoCapture(0)` to access the webcam and capture a live video stream.\n",
    "- **Hand Detection:** For each frame, hands are detected and their landmarks are retrieved.\n",
    "- **Finger Counting:** By checking the position of each landmark, we determine if a finger is raised. \n",
    "- **Display:** The total number of fingers raised is shown on the frame using OpenCV's `putText` method.\n",
    "\n",
    "This system can handle multiple hands, and it updates the finger count dynamically as the hands move.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to create a real-time finger-counting system using **OpenCV** and **MediaPipe**. By leveraging state-of-the-art hand tracking algorithms, we can accurately detect hand landmarks and identify which fingers are raised in a live video stream.\n",
    "\n",
    "### Possible Extensions:\n",
    "- **Gesture Recognition:** Extend the system to detect specific hand gestures.\n",
    "- **Sign Language Recognition:** Adapt the code to recognize individual sign language letters or words.\n",
    "- **Touchless Control Systems:** Use this method to implement gesture-based interfaces for controlling software or hardware.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
